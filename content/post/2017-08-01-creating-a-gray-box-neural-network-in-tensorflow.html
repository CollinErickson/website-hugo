---
title: Creating a gray box neural network in TensorFlow
author: Collin Erickson
date: '2017-08-01'
slug: ''
categories: []
tags: [TensorFlow]
---



<p>Generally neural networks act as black boxes. The input goes in, you get output, and there is interpretation of the data that helps you understand the model.</p>
<p>A gray box means that we impose structure on the internal structure of the neural network, so that after the model is fit we can look at the estimated parameters and they will tell us something useful.</p>
<p>One way we can do this is to encode an equation that we want to use near the end of the neural network.</p>
<p>For example, if I know that <span class="math inline">\(y=a e^{cx} + b\)</span>, I can have <span class="math inline">\(c\)</span> be a variable, multiply <span class="math inline">\(x\)</span> by it, use the exponential as the activation function, then do a linear layer to the output.</p>
<p>I will try to implement this example by adapting the linear regression model found <a href="https://www.tensorflow.org/get_started/get_started">here</a>. The only changes I make are to add a third variable and change the equation for <code>linear_model</code>, now called <code>exp_model</code>. I also made minor changes such as changing the loss from sum to mean, and the print out.</p>
<p>I am using Python for this instead of R to make that I have all of the functionality. I’m writing this in RStudio as a Rmarkdown notebook, which conveniently lets you run Python code.</p>
<div id="first-model" class="section level2">
<h2>First model</h2>
<p>The first two lines of code are just to hide the warnings from TF which get annoying quickly as recommended <a href="https://github.com/tensorflow/tensorflow/issues/7778">here</a>. Notice that I have to have this, as well as the loading code such as <code>import tensorflow as tf</code> in every chunk. I guess Python chunks are all run separately.</p>
<pre class="python"><code>import os
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]=&#39;2&#39;
import numpy as np
import tensorflow as tf

# Model parameters
a = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
c = tf.Variable([-.3], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
exp_model = a * tf.exp(c * x) + b
y = tf.placeholder(tf.float32)
# loss
loss = tf.reduce_mean(tf.square(exp_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)
# training data
x_train = [1,2,3,4]
y_train = [0,-1,-2,-3]
# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(1000):
  sess.run(train, {x:x_train, y:y_train})

# evaluate training accuracy
#curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x:x_train, y:y_train})
#print(&quot;W: %s b: %s loss: %s&quot;%(curr_W, curr_b, curr_loss))
curr_a, curr_b, curr_c, curr_loss = sess.run([a, b, c, loss], {x:x_train, y:y_train})
sess.close()
print(&quot;a: %s \nb: %s \nc: %s \nloss: %s&quot;%(curr_a, curr_b, curr_c, curr_loss))</code></pre>
<pre><code>## a: [ 2.57894111] 
## b: [-2.33267903] 
## c: [-0.494257] 
## loss: 0.457323</code></pre>
<p>Let me check these values to see how well it matches the data.</p>
<pre class="r"><code>x &lt;- c(1, 2, 3, 4)
y &lt;- c(0, -1, -2, -3)
plot(x, y)

a &lt;- 5.4532733
b &lt;- -3.58833456
c &lt;- -.42571044
curve(a*exp(c*x) + b, add=T, col=2)</code></pre>
<p><img src="/post/2017-08-01-creating-a-gray-box-neural-network-in-tensorflow_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>This actually looks pretty good considering that we forced the model to be nonlinear for data that is exactly linear.</p>
</div>
<div id="using-data-from-an-exponential-function." class="section level2">
<h2>Using data from an exponential function.</h2>
<p>I’ll try it again using data that more closely resembles the function. I’ll create the data by creating random parameter values for a, b, c, and see if the estimated values for these parameters are equal to the original.</p>
<pre class="r"><code>set.seed(0)
a &lt;- .32
b &lt;- -5.6
c &lt;- 4.4
n &lt;- 30
x &lt;- round(runif(30), 2)
y &lt;- round(a*exp(c*x) + b + rnorm(n, 0, 1), 2)
plot(x, y)
curve(a*exp(c*x) + b, add=T, col=2)</code></pre>
<p><img src="/post/2017-08-01-creating-a-gray-box-neural-network-in-tensorflow_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>cat(x, sep=&#39;, &#39;)</code></pre>
<pre><code>## 0.9, 0.27, 0.37, 0.57, 0.91, 0.2, 0.9, 0.94, 0.66, 0.63, 0.06, 0.21, 0.18, 0.69, 0.38, 0.77, 0.5, 0.72, 0.99, 0.38, 0.78, 0.93, 0.21, 0.65, 0.13, 0.27, 0.39, 0.01, 0.38, 0.87</code></pre>
<pre class="r"><code>cat(y, sep=&#39;, &#39;)</code></pre>
<pre><code>## 10.77, -4.3, -4.86, -1.23, 10.7, -5.05, 11.56, 14.55, 1.04, -0.54, -4.68, -3.71, -5.58, -0.22, -3.85, 3.64, -3.25, 1.57, 18.69, -3.17, 5.45, 14.55, -5.22, 1.23, -5.31, -2.79, -3.26, -5.72, -4.73, 7.94</code></pre>
<p>The only change to the script above is that I need to change the input data as below. I’ll also change the number of iterations by a factor of ten to make sure that isn’t a problem.</p>
<pre class="python"><code>import os
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]=&#39;2&#39;
import numpy as np
import tensorflow as tf

# Model parameters
a = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
c = tf.Variable([-.3], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
exp_model = a * tf.exp(c * x) + b
y = tf.placeholder(tf.float32)
# loss
loss = tf.reduce_mean(tf.square(exp_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)
# training data
# x_train = [1,2,3,4]
# y_train = [0,-1,-2,-3]
# NEW DATA
x_train = [0.9, 0.27, 0.37, 0.57, 0.91, 0.2, 0.9, 0.94, 0.66, 0.63, 0.06, 0.21, 0.18, 0.69, 0.38, 0.77, 0.5, 0.72, 0.99, 0.38, 0.78, 0.93, 0.21, 0.65, 0.13, 0.27, 0.39, 0.01, 0.38, 0.87]
y_train = [10.77, -4.3, -4.86, -1.23, 10.7, -5.05, 11.56, 14.55, 1.04, -0.54, -4.68, -3.71, -5.58, -0.22, -3.85, 3.64, -3.25, 1.57, 18.69, -3.17, 5.45, 14.55, -5.22, 1.23, -5.31, -2.79, -3.26, -5.72, -4.73, 7.94]

# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(10000):
  sess.run(train, {x:x_train, y:y_train})

# evaluate training accuracy
curr_a, curr_b, curr_c, curr_loss = sess.run([a, b, c, loss], {x:x_train, y:y_train})
print(&quot;a: %s \nb: %s \nc: %s \nloss: %s&quot;%(curr_a, curr_b, curr_c, curr_loss))</code></pre>
<pre><code>## a: [-32.52795029] 
## b: [ 21.62292099] 
## c: [-1.09328878] 
## loss: 16.1457</code></pre>
<p>The values it outputs, shown below, are nowhere near the input values.</p>
<pre class="r"><code>plot(x, y)

a &lt;- -32.52795029
b &lt;- 21.62292099
c &lt;- -1.09328878
curve(a*exp(c*x) + b, add=T, col=2)</code></pre>
<p><img src="/post/2017-08-01-creating-a-gray-box-neural-network-in-tensorflow_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>And the plot shows that it looks terrible. I tried restarting it with different starting values and it was still horrible.</p>
</div>
<div id="noiseless-exponential-data" class="section level2">
<h2>Noiseless exponential data</h2>
<p>Let me try again but with no noise in the data.</p>
<pre class="r"><code>y_nonoise &lt;- round(a*exp(c*x) + b + rnorm(n, 0, 1), 2)
cat(y_nonoise, sep=&#39;, &#39;)</code></pre>
<pre><code>## 8.4, -4.15, 1.07, 5.01, 9.37, -4.25, 9.09, 12.42, 5.02, 5.23, -8.59, -3.61, -5.27, 4.1, -1.11, 7.96, 2.78, 5.88, 10.49, -0.66, 8, 8.43, -3.87, 5.89, -6.53, -2.57, 0.64, -11.2, 0.03, 9.72</code></pre>
<p>The full code is below, I reduced the number of iterations back to the original value.</p>
<pre class="python"><code>import os
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]=&#39;2&#39;
import numpy as np
import tensorflow as tf

# Model parameters
a = tf.Variable([.0], dtype=tf.float32)
b = tf.Variable([-.0], dtype=tf.float32)
c = tf.Variable([.0], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
exp_model = a * tf.exp(c * x) + b
y = tf.placeholder(tf.float32)
# loss
loss = tf.reduce_mean(tf.square(exp_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)
# training data
# NEW DATA NO NOISE
x_train = [0.9, 0.27, 0.37, 0.57, 0.91, 0.2, 0.9, 0.94, 0.66, 0.63, 0.06, 0.21, 0.18, 0.69, 0.38, 0.77, 0.5, 0.72, 0.99, 0.38, 0.78, 0.93, 0.21, 0.65, 0.13, 0.27, 0.39, 0.01, 0.38, 0.87]
y_train = [10.12, -6.11, -2.81, -0.84, 11.71, -4.56, 10.81, 16.86, -0.56, -0.54, -4.93, -4.18, -5.07, -1.16, -5.16, 4.23, -2.72, 1.06, 19.23, -4.71, 4.54, 12.13, -4.43, 0.24, -4.97, -4.53, -3.56, -5.91, -4.02, 9.77]

# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(1000):
  sess.run(train, {x:x_train, y:y_train})

# evaluate training accuracy

curr_a, curr_b, curr_c, curr_loss = sess.run([a, b, c, loss], {x:x_train, y:y_train})
print(&quot;a: %s \nb: %s \nc: %s \nloss: %s&quot;%(curr_a, curr_b, curr_c, curr_loss))
</code></pre>
<pre><code>## a: [-13.35965538] 
## b: [ 6.38554287] 
## c: [-1.93131614] 
## loss: 27.3156</code></pre>
<p>The output is still awful. No clue why this is happening.</p>
</div>
<div id="change-of-parameters" class="section level2">
<h2>Change of parameters</h2>
<p>Let me try one more time, but with no randomness, <span class="math inline">\(c\)</span> more negative, and <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> smaller.</p>
<pre class="r"><code>set.seed(0)
a &lt;- 1.32
b &lt;- -0.6
c &lt;- -4.4
n &lt;- 30
x &lt;- round(runif(30), 2)
y &lt;- round(a*exp(c*x) + b , 2)
plot(x, y)
curve(a*exp(c*x) + b, add=T, col=2)</code></pre>
<p><img src="/post/2017-08-01-creating-a-gray-box-neural-network-in-tensorflow_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>cat(y, sep=&#39;, &#39;)</code></pre>
<pre><code>## -0.57, -0.2, -0.34, -0.49, -0.58, -0.05, -0.57, -0.58, -0.53, -0.52, 0.41, -0.08, 0, -0.54, -0.35, -0.56, -0.45, -0.54, -0.58, -0.35, -0.56, -0.58, -0.08, -0.52, 0.15, -0.2, -0.36, 0.66, -0.35, -0.57</code></pre>
<pre class="python"><code>import os
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]=&#39;2&#39;
import numpy as np
import tensorflow as tf

# Model parameters
a = tf.Variable([.0], dtype=tf.float32)
b = tf.Variable([-.0], dtype=tf.float32)
c = tf.Variable([.0], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
exp_model = a * tf.exp(c * x) + b
y = tf.placeholder(tf.float32)
# loss
loss = tf.reduce_mean(tf.square(exp_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)
# training data
x_train = [0.9, 0.27, 0.37, 0.57, 0.91, 0.2, 0.9, 0.94, 0.66, 0.63, 0.06, 0.21, 0.18, 0.69, 0.38, 0.77, 0.5, 0.72, 0.99, 0.38, 0.78, 0.93, 0.21, 0.65, 0.13, 0.27, 0.39, 0.01, 0.38, 0.87]
y_train = [-0.57, -0.2, -0.34, -0.49, -0.58, -0.05, -0.57, -0.58, -0.53, -0.52, 0.41, -0.08, 0, -0.54, -0.35, -0.56, -0.45, -0.54, -0.58, -0.35, -0.56, -0.58, -0.08, -0.52, 0.15, -0.2, -0.36, 0.66, -0.35, -0.57]

# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(1000):
  sess.run(train, {x:x_train, y:y_train})

# evaluate training accuracy
curr_a, curr_b, curr_c, curr_loss = sess.run([a, b, c, loss], {x:x_train, y:y_train})
print(&quot;a: %s \nb: %s \nc: %s \nloss: %s&quot;%(curr_a, curr_b, curr_c, curr_loss))</code></pre>
<pre><code>## a: [-0.26286733] 
## b: [-0.0292428] 
## c: [ 0.33243284] 
## loss: 0.08065</code></pre>
<p>These results are a little less egregious.</p>
<p>This curve does not look that good. I’m giving up for today.</p>
<pre class="r"><code>plot(x, y)

a &lt;- -0.26286733
b &lt;- -0.0292428
c &lt;- 0.33243284
curve(a*exp(c*x) + b, add=T, col=2)</code></pre>
<p><img src="/post/2017-08-01-creating-a-gray-box-neural-network-in-tensorflow_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
<div id="better-starting-values" class="section level2">
<h2>Better starting values</h2>
<p>What if I start if with near correct values? We don’t want it to be too sensitive to initial values, but if this doesn’t work then it is hopeless.</p>
<pre class="python"><code>import os
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]=&#39;2&#39;
import numpy as np
import tensorflow as tf

# Model parameters
a = tf.Variable([1.3], dtype=tf.float32)
b = tf.Variable([-.59], dtype=tf.float32)
c = tf.Variable([-4.3], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
exp_model = a * tf.exp(c * x) + b
y = tf.placeholder(tf.float32)
# loss
loss = tf.reduce_mean(tf.square(exp_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)
# training data
x_train = [0.9, 0.27, 0.37, 0.57, 0.91, 0.2, 0.9, 0.94, 0.66, 0.63, 0.06, 0.21, 0.18, 0.69, 0.38, 0.77, 0.5, 0.72, 0.99, 0.38, 0.78, 0.93, 0.21, 0.65, 0.13, 0.27, 0.39, 0.01, 0.38, 0.87]
y_train = [-0.57, -0.2, -0.34, -0.49, -0.58, -0.05, -0.57, -0.58, -0.53, -0.52, 0.41, -0.08, 0, -0.54, -0.35, -0.56, -0.45, -0.54, -0.58, -0.35, -0.56, -0.58, -0.08, -0.52, 0.15, -0.2, -0.36, 0.66, -0.35, -0.57]

# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(10000):
  sess.run(train, {x:x_train, y:y_train})

# evaluate training accuracy
curr_a, curr_b, curr_c, curr_loss = sess.run([a, b, c, loss], {x:x_train, y:y_train})
print(&quot;a: %s \nb: %s \nc: %s \nloss: %s&quot;%(curr_a, curr_b, curr_c, curr_loss))
</code></pre>
<pre><code>## a: [ 1.31232285] 
## b: [-0.60362089] 
## c: [-4.31497335] 
## loss: 1.4961e-05</code></pre>
<p>This gives values close to the truth.</p>
<p>How about a little further away?</p>
<pre class="python"><code>import os
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]=&#39;2&#39;
import numpy as np
import tensorflow as tf

# Model parameters
a = tf.Variable([1.6], dtype=tf.float32)
b = tf.Variable([-.9], dtype=tf.float32)
c = tf.Variable([-3.6], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
exp_model = a * tf.exp(c * x) + b
y = tf.placeholder(tf.float32)
# loss
loss = tf.reduce_mean(tf.square(exp_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)
# training data
x_train = [0.9, 0.27, 0.37, 0.57, 0.91, 0.2, 0.9, 0.94, 0.66, 0.63, 0.06, 0.21, 0.18, 0.69, 0.38, 0.77, 0.5, 0.72, 0.99, 0.38, 0.78, 0.93, 0.21, 0.65, 0.13, 0.27, 0.39, 0.01, 0.38, 0.87]
y_train = [-0.57, -0.2, -0.34, -0.49, -0.58, -0.05, -0.57, -0.58, -0.53, -0.52, 0.41, -0.08, 0, -0.54, -0.35, -0.56, -0.45, -0.54, -0.58, -0.35, -0.56, -0.58, -0.08, -0.52, 0.15, -0.2, -0.36, 0.66, -0.35, -0.57]

# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(10000):
  sess.run(train, {x:x_train, y:y_train})

# evaluate training accuracy
curr_a, curr_b, curr_c, curr_loss = sess.run([a, b, c, loss], {x:x_train, y:y_train})
print(&quot;a: %s \nb: %s \nc: %s \nloss: %s&quot;%(curr_a, curr_b, curr_c, curr_loss))
</code></pre>
<pre><code>## a: [ 1.2807374] 
## b: [-0.63670284] 
## c: [-3.75594163] 
## loss: 0.000446578</code></pre>
<p>This gives nearly the same results are before, which is a good sign.</p>
</div>
<div id="solving-the-problem" class="section level1">
<h1>Solving the problem</h1>
<p>After spending the day using TensorFlow and getting used to it, I figured out what was probably causing the problem. It wasn’t the data or any part of the model coding. Rather it has to do with the parameter optimization.</p>
<p>I should have tried different step sizes, and maybe more iterations if the step size was made too small.</p>
<p>Let me return to the noisy data. I will reduce the step size to 0.001, whereas I had been using 0.01 up until now.</p>
<pre class="python"><code>import os
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]=&#39;2&#39;
import numpy as np
import tensorflow as tf

# Model parameters
a = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
c = tf.Variable([-.3], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
exp_model = a * tf.exp(c * x) + b
y = tf.placeholder(tf.float32)
# loss
loss = tf.reduce_mean(tf.square(exp_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.001)
train = optimizer.minimize(loss)
# training data
# x_train = [1,2,3,4]
# y_train = [0,-1,-2,-3]
# NEW DATA
x_train = [0.9, 0.27, 0.37, 0.57, 0.91, 0.2, 0.9, 0.94, 0.66, 0.63, 0.06, 0.21, 0.18, 0.69, 0.38, 0.77, 0.5, 0.72, 0.99, 0.38, 0.78, 0.93, 0.21, 0.65, 0.13, 0.27, 0.39, 0.01, 0.38, 0.87]
y_train = [10.77, -4.3, -4.86, -1.23, 10.7, -5.05, 11.56, 14.55, 1.04, -0.54, -4.68, -3.71, -5.58, -0.22, -3.85, 3.64, -3.25, 1.57, 18.69, -3.17, 5.45, 14.55, -5.22, 1.23, -5.31, -2.79, -3.26, -5.72, -4.73, 7.94]

# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(10000):
  sess.run(train, {x:x_train, y:y_train})

# evaluate training accuracy
curr_a, curr_b, curr_c, curr_loss = sess.run([a, b, c, loss], {x:x_train, y:y_train})
print(&quot;a: %s \nb: %s \nc: %s \nloss: %s&quot;%(curr_a, curr_b, curr_c, curr_loss))</code></pre>
<pre><code>## a: [ 0.33135614] 
## b: [-5.52935982] 
## c: [ 4.34632301] 
## loss: 0.598727</code></pre>
<pre class="r"><code>x &lt;- c(0.9, 0.27, 0.37, 0.57, 0.91, 0.2, 0.9, 0.94, 0.66, 0.63, 0.06, 0.21, 0.18, 0.69, 0.38, 0.77, 0.5, 0.72, 0.99, 0.38, 0.78, 0.93, 0.21, 0.65, 0.13, 0.27, 0.39, 0.01, 0.38, 0.87)
y &lt;- c(10.77, -4.3, -4.86, -1.23, 10.7, -5.05, 11.56, 14.55, 1.04, -0.54, -4.68, -3.71, -5.58, -0.22, -3.85, 3.64, -3.25, 1.57, 18.69, -3.17, 5.45, 14.55, -5.22, 1.23, -5.31, -2.79, -3.26, -5.72, -4.73, 7.94)
a &lt;- 0.33135614
b &lt;- -5.52935982
c &lt;- 4.34632301
plot(x, y)
curve(a*exp(c*x)+b, add=T, col=2)</code></pre>
<p><img src="/post/2017-08-01-creating-a-gray-box-neural-network-in-tensorflow_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>We can see that it is a perfect fit. The whole time that I thought there was a problem, it was just a parameter selection issue.</p>
</div>
<div id="how-i-should-have-seen-this-problem-earlier" class="section level1">
<h1>How I should have seen this problem earlier</h1>
<p>If I had printed the loss after each iteration, I probably would have seen something fishy. It probably would jump around a lot since the step size was too big, or else it would still be in the process of decreasing and need more time to converge. Let me try the original model again with the big step size 0.01 and print out the loss after each iteration.</p>
<pre class="python"><code>import os
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]=&#39;2&#39;
import numpy as np
import tensorflow as tf

# Model parameters
a = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
c = tf.Variable([-.3], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
exp_model = a * tf.exp(c * x) + b
y = tf.placeholder(tf.float32)
# loss
loss = tf.reduce_mean(tf.square(exp_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)
# training data
# x_train = [1,2,3,4]
# y_train = [0,-1,-2,-3]
# NEW DATA
x_train = [0.9, 0.27, 0.37, 0.57, 0.91, 0.2, 0.9, 0.94, 0.66, 0.63, 0.06, 0.21, 0.18, 0.69, 0.38, 0.77, 0.5, 0.72, 0.99, 0.38, 0.78, 0.93, 0.21, 0.65, 0.13, 0.27, 0.39, 0.01, 0.38, 0.87]
y_train = [10.77, -4.3, -4.86, -1.23, 10.7, -5.05, 11.56, 14.55, 1.04, -0.54, -4.68, -3.71, -5.58, -0.22, -3.85, 3.64, -3.25, 1.57, 18.69, -3.17, 5.45, 14.55, -5.22, 1.23, -5.31, -2.79, -3.26, -5.72, -4.73, 7.94]

# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(10000):
  if i%500 == 0:
    loss_i = sess.run(loss, {x:x_train, y:y_train})
    print(&quot;Iter %d:\tLoss: %.3f&quot;%(i, loss_i))
  sess.run(train, {x:x_train, y:y_train})

# evaluate training accuracy
curr_a, curr_b, curr_c, curr_loss = sess.run([a, b, c, loss], {x:x_train, y:y_train})
print(&quot;a: %s \nb: %s \nc: %s \nloss: %s&quot;%(curr_a, curr_b, curr_c, curr_loss))</code></pre>
<pre><code>## Iter 0:  Loss: 52.006
## Iter 500:    Loss: 29.149
## Iter 1000:   Loss: 22.839
## Iter 1500:   Loss: 19.896
## Iter 2000:   Loss: 18.262
## Iter 2500:   Loss: 17.230
## Iter 3000:   Loss: 16.515
## Iter 3500:   Loss: 15.986
## Iter 4000:   Loss: 15.575
## Iter 4500:   Loss: 15.245
## Iter 5000:   Loss: 14.971
## Iter 5500:   Loss: 14.740
## Iter 6000:   Loss: 14.542
## Iter 6500:   Loss: 14.368
## Iter 7000:   Loss: 14.215
## Iter 7500:   Loss: 14.079
## Iter 8000:   Loss: 13.956
## Iter 8500:   Loss: 15.746
## Iter 9000:   Loss: 15.996
## Iter 9500:   Loss: 16.102
## a: [-32.52795029] 
## b: [ 21.62292099] 
## c: [-1.09328878] 
## loss: 16.1457</code></pre>
<p>It looks like the loss decreased for the first 8,000 iterations, then started increasing again. More iterations might not have helped since it looks like it started to diverge. Divergence is a sign that a smaller step size is needed.</p>
</div>
