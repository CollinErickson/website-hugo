---
title: What is spectral clustering?
author: Collin Erickson
date: '2018-10-26'
slug: what-is-spectral-clustering
categories: []
tags: [clustering, data science]
---

I had never heard of spectral clustering until last week.
Then I came across
[this image](http://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_001.png)
comparing 9 clustering algorithms on different 2D datasets.

![](http://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_001.png)

It appeared to me that spectral clustering did the best across all the data,
and I realized that the only clustering algorithm I understood was k-means.
(DBSCAN might be better based on the results shown, but one step at a time.)
So here I'm going to try to figure out what spectral clustering is and how I can implement it.

## Create data

I'm going to create a dataset to have something to work with as I go.
I'm going to make it very easy.

```{r}
set.seed(0)
n <- 100
x1 <- matrix(rnorm(2*n), n, 2)
x2 <- sweep(matrix(rnorm(2*n), n, 2), 2, c(-5,0))
x <- rbind(cbind(x1,1), cbind(x2, 2))
x <- data.frame(x)
x[,3] <- as.factor(x[,3])
names(x)[3] <- "group"
library(ggplot2)
ggplot(data=x, mapping=aes(x=X1, y=X2, color=group)) + geom_point()
```

## Similarity matrix

First we have to create the similarity matrix.
We can use a Gaussian measure to determine the similarity.

```{r}
S <- outer(1:n, 1:n, Vectorize(function(i,j, sig=1) {exp(-sum((x[i,1:2]-x[j,1:2])^2)/2/sig^2)}))
```

```{r}
image(S)
```


## Weighted adjacency matrix

This is where it starts to get very complicated.
We need a weighted adjacency matrix to determine which points are close to each other.
There are a couple of different to create this matrix.

We can use the similarity matrix as our weighted adjacency matrix since we
are using the Gaussian for similarity.

```{r}
W <- S
```

